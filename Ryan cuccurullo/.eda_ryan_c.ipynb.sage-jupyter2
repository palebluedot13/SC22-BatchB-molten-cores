{"backend_state":"init","connection_file":"/projects/afffd160-11c4-4b0e-8185-cf29c729cf98/.local/share/jupyter/runtime/kernel-c0d00052-c962-494e-b700-586b08766d95.json","kernel":"ds_env","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"221d86","input":"px.scatter(df, x='danceability', y='loudness', template=\"plotly_dark\", color='popularity')\n\n# popular songs are around 0 to -15 loudness\n# popular danceable songs are closer to 0 loudness\n# non danceable songs tend to be more unpopular than danceable songs\n# as danceability increases, the loudness compresses","pos":24,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"305d86","input":"#df = df.sort_values(by=[\"music_genre_name\"])\n\npx.bar(df.sort_values(by=[\"music_genre_name\"]), x='popularity', y='acousticness', color='music_genre_name')\n\n# non danceable songs are of the highest acoustecness\n# danceability and popularity are not correlated\n# for each popularity, the least danceable songs tend to have the highest acousticness (at least until about 45 popularity)***","pos":25,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"331318","input":"px.scatter_matrix(df, dimensions = [\"loudness\", \"energy\", \"danceability\", \"acousticness\"], color = \"music_genre\", template=\"plotly_dark\")","pos":19,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"467a58","input":"#histogram showing number of songs per genre\ndf[\"music_genre_name\"].hist(figsize = (10, 10))","pos":15,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"4a11d2","input":"","pos":16,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"4f9dea","input":"","pos":30,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"502fd0","input":"px.scatter_3d(df, x = \"speechiness\", y = \"duration_ms\", z = \"popularity\", color = \"music_genre\", template = \"plotly_dark\")\n\n# alternative and country are extremely similar here\n# rock popularity > 50; duration < 1M; speechiness < .6\n# blues popularity < 50; duration ~< 1M; speechiness < .6\n    # separated by rock by ppularity (and few outliers in popularity and duration)\n# classical has widest range of popularity and comparitively wide range of duration and fairly wide range of speechiness (overall widest ranges)\n\n# distinct genre differences:\n    # Classical vs Hip Hop\n    # Rock vs Blues\n    # Electronic vs Hip Hop\n    # Electronic vs Rock\n    # Alternative vs Classical\n    # Rap vs Classical\n    # Rap vs Rock\n    # Country vs Anime\n    # Jazz vs Hip Hop\n    # Jazz vs Rock\n    # Jazz vs Rap\n    # Anime vs Jazz (?)\n    # Alternative vs Anime\n    # Anime vs Hip Hop","pos":17,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"575d29","input":"","pos":32,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"6b2b5d","input":"px.scatter(df, x = \"danceability\", y = \"loudness\", color = \"music_genre\", template=\"plotly_dark\")","pos":23,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"74896b","input":"px.scatter(df, x='loudness', y='energy', template=\"plotly_dark\", color='popularity')\n\n# loudness and energy are positively correlated\n# louder songs are more popular\n# higher energy songs are more popular\n# the most popular songs are both loud and energetic\n# maximum loudness and maximum energy decrease popularity","pos":22,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"7612ff","input":"","pos":34,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"8ff5b6","input":"px.scatter(df, x = \"danceability\", y = \"acousticness\", color = \"music_genre\", template=\"plotly_dark\")","pos":26,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"9a5b13","input":"df = df.sort_values(by=[\"acousticness\"])\n\npx.bar(df, x='popularity', y='acousticness', template=\"plotly_dark\",color='music_genre')\n\n# as popularity increases, average acousticness decreases after popularity of 35\n    # as popularity increases to 35, average acousticness increases\n# non popular songs also have low acousticness\n    # popularity of 20 or less have acousticness of below 100\n# know that songs with popularity of 0 have full range of acousticness","pos":28,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"a0e83d","input":"","pos":20,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"ac5efa","input":"#px.bar(confusion_matrix(y_test, y_hat), x=y_test, y=y_hat, color=y_hat)","pos":10,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"bf2412","input":"","pos":33,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"d75473","input":"","pos":31,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"ec2dfa","input":"px.scatter(df, x = \"loudness\", y = \"instrumentalness\", color = \"music_genre\", template=\"plotly_dark\")","pos":21,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"f5cf3f","input":"px.scatter(df, x='danceability', y='acousticness', template=\"plotly_dark\", color='popularity')\n\n# highly popular danceable songs are low acoustic\n# non popular danceable songs are high acoustic\n# overall high acousticness correlates with low popularity and low acousticness correlates with high popularity\n# danceability and acousticness are not correlated","pos":27,"type":"cell"}
{"cell_type":"code","exec_count":1,"id":"4e524f","input":"#makes it so tempo is in acending order\ndf = df.sort_values(by=[\"tempo\"])\n\npx.scatter(df.sort_values(by=[\"tempo\"]), x = \"loudness\", y = \"tempo\", color = \"music_genre_name\", size=\"duration_ms\",size_max=50,trendline=\"lowess\")\n","output":{"0":{"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#makes it so tempo is in acending order\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtempo\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m px\u001b[38;5;241m.\u001b[39mscatter(df, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloudness\u001b[39m\u001b[38;5;124m\"\u001b[39m, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtempo\u001b[39m\u001b[38;5;124m\"\u001b[39m, color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmusic_genre_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration_ms\u001b[39m\u001b[38;5;124m\"\u001b[39m,size_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,trendline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlowess\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}},"pos":18,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"eeaed9","input":"import xgboost as xgb\n\nmodel = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\ny_pred = model.fit(X_train, y_train).predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Overall Accuracy: \", accuracy)\n\ntotal_squared_error = (np.sum((y_test - y_pred)**2))\nmean_squared_error = total_squared_error/len(y_test)\nprint(mean_squared_error)\n\n#confusion matrix\nlabels = ['Electronic', 'Anime', 'Jazz', 'Alternative', 'Country', 'Rap', 'Blues', 'Rock', 'Classical', 'Hip-Hop']\n# sns.heatmap(confusion_matrix(y_test.values.argmax(axis=1), y_pred.argmax(axis=1)), annot=True, fmt='g', xticklabels=labels, yticklabels=labels)\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g', xticklabels=labels, yticklabels=labels)","output":{"0":{"name":"stdout","output_type":"stream","text":"Overall Accuracy:  0.6491\n5.4102\n"},"1":{"data":{"text/plain":"<AxesSubplot:>"},"exec_count":10,"output_type":"execute_result"},"2":{"data":{"image/png":"6e962bd65b42f2367cbb713ac9b9487cd5df2cdd","text/plain":"<Figure size 432x288 with 2 Axes>"},"exec_count":10,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":12,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"85b101","input":"print((np.sum((y_test - y_pred)**2))/len(y_test) )#mean squared error\nprint(f1_score(y_test, y_pred, average=None))\nprint(classification_report(y_test, y_pred,target_names=[i+\":\" for i in labels]))","output":{"0":{"name":"stdout","output_type":"stream","text":"5.4102\n[0.72033455 0.80696365 0.63120567 0.53474801 0.67105263 0.4841386\n 0.6724846  0.64254192 0.85818182 0.49171009]\n              precision    recall  f1-score   support\n\n Electronic:       0.74      0.70      0.72       981\n      Anime:       0.83      0.78      0.81      1008\n       Jazz:       0.64      0.63      0.63       996\nAlternative:       0.57      0.51      0.53       996\n    Country:       0.69      0.65      0.67      1021\n        Rap:       0.46      0.51      0.48       977\n      Blues:       0.70      0.65      0.67      1012\n       Rock:       0.57      0.74      0.64       984\n  Classical:       0.87      0.85      0.86       972\n    Hip-Hop:       0.49      0.49      0.49      1053\n\n    accuracy                           0.65     10000\n   macro avg       0.66      0.65      0.65     10000\nweighted avg       0.66      0.65      0.65     10000\n\n"}},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"8a719d","input":"\ndf = df.sort_values(by=[\"key\"])\npx.bar(df, x='music_genre_name', y='tempo',color='key',template=\"plotly_dark\")\n\n# tempo is highest for classical\n# tempo is lowest for electronic\n# clear pattern in tempo per genre","output":{"0":{"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m px\u001b[38;5;241m.\u001b[39mbar(df, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmusic_genre_name\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtempo\u001b[39m\u001b[38;5;124m'\u001b[39m,color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m,template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplotly_dark\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}},"pos":29,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"5ce0cd","input":"#importing datasets\nmusic_data = pd.read_csv(\"music_genre.csv\")\ndf = music_data.copy(deep=True)\n\n#dropping columns\nbadInfo = [\"instance_id\",\"obtained_date\",\"artist_name\",\"track_name\"]\ndf.drop(columns=badInfo,axis=1,inplace=True)\n\n#dropping null rows\ndf.dropna(inplace=True)\ndf.reset_index(drop=True, inplace=True) #Very good practice to reset how your rows are counted when you drop rows.\n\n#fixing tempo\ndf[\"tempo\"]=df[\"tempo\"].replace(\"?\",np.nan)\ndf[\"tempo\"] = df[\"tempo\"].astype(\"float\")\ndf[\"tempo\"]=df.groupby(\"music_genre\")[\"tempo\"].transform(lambda x: x.fillna(x.mean(skipna=True)))\ndf['tempo'] = np.around(df['tempo'],2)\n\n#fixing duration\ndf[\"duration_ms\"]=df[\"duration_ms\"].replace(-1.0,np.nan)\ndf[\"duration_ms\"]=df.groupby(\"music_genre\")[\"duration_ms\"].transform(lambda x: x.fillna(x.mean(skipna=True)))\ndf['duration_ms'] = np.around(df['duration_ms'],2)\n\n\n#change the values from string to int\ndf['key'] = stringToInt(df,'key')\ndf['mode'] = stringToInt(df,'mode')\ndf['music_genre_name'] = df['music_genre']\ndf['music_genre'] = stringToInt(df,'music_genre')","output":{"0":{"ename":"NameError","evalue":"name 'pd' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#importing datasets\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m music_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmusic_genre.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m music_data\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#dropping columns\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"0603f6","input":"\nimport pandas as pd\nimport plotly.express as px\nimport numpy as np\nimport plotly.io as pio\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import make_scorer, f1_score, accuracy_score, confusion_matrix, classification_report,roc_curve, roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import LinearSVC\nimport seaborn as sns\n\nfrom sklearn import preprocessing\n\n#makes theme dark for all ploty visuals\npio.templates.default = \"plotly_dark\"\n","pos":3,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"491416","input":"\nX = df.loc[:,df.columns[:-2]]#input_columns\ny= df['music_genre']#what we want\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\nsc = preprocessing.StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform (X_test)\n\n# gnb = GaussianNB()\n# y_hat = gnb.fit(X_train, y_train).predict(X_test)\n# total_squared_error = (np.sum((y_test - y_hat)**2)) #get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\n# mean_squared_error = total_squared_error/len(y_test) #divide this by how many rows/observations we have \n\n\n\n\n# labels = ['Electronic', 'Anime', 'Jazz', 'Alternative', 'Country', 'Rap', 'Blues', 'Rock', 'Classical', 'Hip-Hop']\n\n# print(mean_squared_error)\n# print(f1_score(y_test, y_hat, average=None))\n# print(classification_report(y_test, y_hat, labels=[i for i in range(len(labels))]))\n\n\n# sns.heatmap(confusion_matrix(y_test, y_hat), annot=True, fmt='g', xticklabels=labels, yticklabels=labels)\n","pos":9,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"9c7488","input":"def stringToInt(dataFrame,col):\n    test = {}\n    for i in dict(enumerate(dataFrame[col].unique())).items():#is a dictionary of the keys and corespodening number\n        #makes it so the keys and values of the dictionary switch\n        test[i[1]]=i[0]\n    print(test,'\\n')\n    return dataFrame[col].map(test)","pos":5,"type":"cell"}
{"cell_type":"markdown","id":"17a781","input":"# visuals:\n\n","pos":14,"type":"cell"}
{"cell_type":"markdown","id":"25717c","input":"# [Markdown Guide cheat Sheet](https://www.markdownguide.org/cheat-sheet/)\n\n","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"3705dd","input":"# Naïve Bayes","pos":8,"type":"cell"}
{"cell_type":"markdown","id":"9aa279","input":"## Dropping things:\n\n","pos":6,"type":"cell"}
{"cell_type":"markdown","id":"9d0875","input":"## Functions","pos":4,"type":"cell"}
{"cell_type":"markdown","id":"bba42e","input":"# Info:\n\n- ### instrumentalness: vocals in a track\n\n- ### speechiness: detects the pressents of vocal words in a track\n\n- ### music genre: 10 different types\n\t0. Electronic\n    1. Classical\n    2. Jazz\n    3. anime\n    4. Rock\n    5. country\n    6. Rap\n    7. Blues\n    8. Hip-Hop\n    9.Alternative\n\n# problems with table:\n\n1. ~~negative duration~~\n2. ~~missing tempos~~\n3. ~~rows 10000-10005 are nan values for every column~~\n4. negative loudness\n\n","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"cc9b7a","input":"## imports","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"eaae39","input":"# xgboost","pos":11,"type":"cell"}
{"id":0,"time":1657295139186,"type":"user"}
{"last_load":1657299260572,"type":"file"}