{"backend_state":"running","connection_file":"/projects/afffd160-11c4-4b0e-8185-cf29c729cf98/.local/share/jupyter/runtime/kernel-2ea180e4-9d5d-49a4-8dc7-db503afd7459.json","kernel":"ds_env","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1657207425323,"exec_count":108,"id":"9c7488","input":"def stringToInt(dataFrame,col):\n    test = {}\n    for i in dict(enumerate(dataFrame[col].unique())).items():#is a dictionary of the keys and corespodening number\n        #makes it so the keys and values of the dictionary switch\n        test[i[1]]=i[0]\n    print(test,'\\n')\n    return dataFrame[col].map(test)","kernel":"ds_env","pos":3,"start":1657207425319,"state":"done","type":"cell"}
{"cell_type":"code","end":1657208911240,"exec_count":128,"id":"467a58","input":"#histogram showing number of songs per genre\ndf[\"music_genre\"].hist(figsize = (10, 10))","kernel":"ds_env","output":{"0":{"data":{"text/plain":"<AxesSubplot:>"},"exec_count":128},"1":{"data":{"image/png":"4877ce540eac8ceba5e636be1dd545e27607f683","text/plain":"<Figure size 720x720 with 1 Axes>"}}},"pos":23,"scrolled":true,"start":1657208910804,"state":"done","type":"cell"}
{"cell_type":"code","end":1657214616145,"exec_count":131,"id":"0603f6","input":"\nimport pandas as pd\nimport plotly.express as px\nimport numpy as np\nimport plotly.io as pio\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import make_scorer, f1_score, accuracy_score, confusion_matrix, classification_report,roc_curve, roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import LinearSVC\n\nfrom sklearn import preprocessing\n\n#makes theme dark for all ploty visuals\npio.templates.default = \"plotly_dark\"\n","kernel":"ds_env","pos":2,"scrolled":true,"start":1657214616117,"state":"done","type":"cell"}
{"cell_type":"code","end":1657219706430,"exec_count":166,"id":"491416","input":"#col = \nX = df.loc[:,df.columns[:-2]]#input_columns\ny= df['music_genre']#what we want\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\nsc = preprocessing.StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform (X_test)\n\ngnb = GaussianNB()\ny_hat = gnb.fit(X_train, y_train).predict(X_test)\ntotal_squared_error = (np.sum((y_test - y_hat)**2)) #get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\nmean_squared_error = total_squared_error/len(y_test) #divide this by how many rows/observations we have \n\n\n\n\nlabels = ['Electronic', 'Anime', 'Jazz', 'Alternative', 'Country', 'Rap', 'Blues', 'Rock', 'Classical', 'Hip-Hop']\n\nprint(mean_squared_error)\nprint(f1_score(y_test, y_hat, average=None))\nprint(classification_report(y_test, y_hat, labels=[i for i in range(len(labels))]))\n\n\nsns.heatmap(confusion_matrix(y_test, y_hat), annot=True, fmt='g', xticklabels=labels, yticklabels=labels)\n","kernel":"ds_env","output":{"0":{"name":"stdout","text":"8.4072\n[0.47667804 0.48765041 0.35509737 0.26208651 0.4291025  0.43430838\n 0.3141503  0.39588378 0.73520249 0.45654163]\n              precision    recall  f1-score   support\n\n           0       0.54      0.43      0.48       981\n           1       0.67      0.38      0.49      1008\n           2       0.41      0.31      0.36       996\n           3       0.36      0.21      0.26       996\n           4       0.29      0.79      0.43      1021\n           5       0.42      0.45      0.43       977\n           6       0.50      0.23      0.31      1012\n           7       0.49      0.33      0.40       984\n           8       0.65      0.85      0.74       972\n           9       0.44      0.47      0.46      1053\n\n    accuracy                           0.45     10000\n   macro avg       0.48      0.45      0.43     10000\nweighted avg       0.48      0.45      0.43     10000\n\n"},"1":{"data":{"text/plain":"<AxesSubplot:>"},"exec_count":166},"2":{"data":{"image/png":"63e864e2a2e049f5a61148343a99101720fa26ab","text/plain":"<Figure size 432x288 with 2 Axes>"}}},"pos":8,"scrolled":false,"start":1657219705230,"state":"done","type":"cell"}
{"cell_type":"code","end":1657219782737,"exec_count":169,"id":"305d86","input":"#df = df.sort_values(by=[\"music_genre_name\"])\n\npx.bar(df.sort_values(by=[\"music_genre_name\"]), x='popularity', y='acousticness', color='music_genre_name')\n\n# non danceable songs are of the highest acoustecness\n# danceability and popularity are not correlated\n# for each popularity, the least danceable songs tend to have the highest acousticness (at least until about 45 popularity)***","kernel":"ds_env","output":{"0":{"data":{"iframe":"25c829232fa6971e898a98891c48a6645dc06136"}}},"pos":33,"start":1657219782042,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"4f9dea","input":"","pos":38,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"575d29","input":"","pos":40,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"5def63","input":"df.shape()","pos":11,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"7612ff","input":"","pos":42,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"a0e83d","input":"","pos":28,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"bf2412","input":"","pos":41,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"d75473","input":"","pos":39,"type":"cell"}
{"cell_type":"code","exec_count":1,"id":"4a11d2","input":"#import plotly.figure_factory as ff\n#ff.create_distplot(df[\"popularity\"], df[\"music_genre\"], bin_size=[.1, .25, .5, 1])","pos":24,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"9a5b13","input":"df = df.sort_values(by=[\"acousticness\"])\n\npx.bar(df, x='popularity', y='acousticness', template=\"plotly_dark\",color='music_genre')\n\n# as popularity increases, average acousticness decreases after popularity of 35\n    # as popularity increases to 35, average acousticness increases\n# non popular songs also have low acousticness\n    # popularity of 20 or less have acousticness of below 100\n# know that songs with popularity of 0 have full range of acousticness","output":{"0":{"data":{"iframe":"53302050ed239614a6b913fba22abad405cea9d1"},"exec_count":10,"output_type":"execute_result"}},"pos":36,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":164,"id":"5ce0cd","input":"#importing datasets\nmusic_data = pd.read_csv(\"music_genre.csv\")\ndf = music_data.copy(deep=True)\n\n#dropping columns\nbadInfo = [\"instance_id\",\"obtained_date\",\"artist_name\",\"track_name\"]\ndf.drop(columns=badInfo,axis=1,inplace=True)\n\n#dropping null rows\ndf.dropna(inplace=True)\ndf.reset_index(drop=True, inplace=True) #Very good practice to reset how your rows are counted when you drop rows.\n\n#fixing tempo\ndf[\"tempo\"]=df[\"tempo\"].replace(\"?\",np.nan)\ndf[\"tempo\"] = df[\"tempo\"].astype(\"float\")\ndf[\"tempo\"]=df.groupby(\"music_genre\")[\"tempo\"].transform(lambda x: x.fillna(x.mean(skipna=True)))\ndf['tempo'] = np.around(df['tempo'],2)\n\n#fixing duration\ndf[\"duration_ms\"]=df[\"duration_ms\"].replace(-1.0,np.nan)\ndf[\"duration_ms\"]=df.groupby(\"music_genre\")[\"duration_ms\"].transform(lambda x: x.fillna(x.mean(skipna=True)))\ndf['duration_ms'] = np.around(df['duration_ms'],2)\n\n\n#change the values from string to int\ndf['key'] = stringToInt(df,'key')\ndf['mode'] = stringToInt(df,'mode')\ndf['music_genre_name'] = df['music_genre']\ndf['music_genre'] = stringToInt(df,'music_genre')","kernel":"ds_env","output":{"0":{"name":"stdout","text":"{'A#': 0, 'D': 1, 'G#': 2, 'C#': 3, 'F#': 4, 'B': 5, 'G': 6, 'F': 7, 'A': 8, 'C': 9, 'E': 10, 'D#': 11} \n\n{'Minor': 0, 'Major': 1} \n\n{'Electronic': 0, 'Anime': 1, 'Jazz': 2, 'Alternative': 3, 'Country': 4, 'Rap': 5, 'Blues': 6, 'Rock': 7, 'Classical': 8, 'Hip-Hop': 9} \n\n"},"1":{"data":{"text/plain":"Index(['popularity', 'acousticness', 'danceability', 'duration_ms', 'energy',\n       'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n       'speechiness', 'tempo', 'valence', 'music_genre'],\n      dtype='object')"},"exec_count":164}},"pos":5,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":20,"id":"331318","input":"px.scatter_matrix(df, dimensions = [\"loudness\", \"energy\", \"danceability\", \"acousticness\"], color = \"music_genre\", template=\"plotly_dark\")","output":{"0":{"data":{"iframe":"55d6b346f58cd05e9b5727af9b27c5b335a39f31"},"exec_count":20,"output_type":"execute_result"}},"pos":27,"type":"cell"}
{"cell_type":"code","exec_count":25,"id":"8a719d","input":"\ndf = df.sort_values(by=[\"key\"])\npx.bar(df, x='music_genre', y='tempo',color='key',template=\"plotly_dark\")\n\n# tempo is highest for classical\n# tempo is lowest for electronic\n# clear pattern in tempo per genre","output":{"0":{"data":{"iframe":"61068620d387cd26d890629fc3f170a2d64ab461"},"exec_count":25,"output_type":"execute_result"}},"pos":37,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":275,"id":"4e524f","input":"#makes it so tempo is in acending order\ndf = df.sort_values(by=[\"tempo\"])\n\npx.scatter(df, x = \"duration_ms\", y = \"tempo\", color = \"music_genre\", template=\"plotly_dark\")\n","output":{"0":{"data":{"iframe":"d7dcdedb86bb333ac68b6911150e8ebc2b9b111a"},"exec_count":275,"output_type":"execute_result"}},"pos":26,"type":"cell"}
{"cell_type":"code","exec_count":277,"id":"ec2dfa","input":"px.scatter(df, x = \"loudness\", y = \"instrumentalness\", color = \"music_genre\", template=\"plotly_dark\")","output":{"0":{"data":{"iframe":"e2a7302b930bfcae9e745108ce9723484bbe539b"},"exec_count":277,"output_type":"execute_result"}},"pos":29,"type":"cell"}
{"cell_type":"code","exec_count":278,"id":"74896b","input":"px.scatter(df, x='loudness', y='energy', template=\"plotly_dark\", color='popularity')\n\n# loudness and energy are positively correlated\n# louder songs are more popular\n# higher energy songs are more popular\n# the most popular songs are both loud and energetic\n# maximum loudness and maximum energy decrease popularity","output":{"0":{"data":{"iframe":"795c2b56c857eb337d6b7779f075668c153ef0a0"},"exec_count":278,"output_type":"execute_result"}},"pos":30,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":279,"id":"6b2b5d","input":"px.scatter(df, x = \"danceability\", y = \"loudness\", color = \"music_genre\", template=\"plotly_dark\")","output":{"0":{"data":{"iframe":"4fd072e40b740c975af358757d0450f0eac73028"},"exec_count":279,"output_type":"execute_result"}},"pos":31,"type":"cell"}
{"cell_type":"code","exec_count":280,"id":"221d86","input":"px.scatter(df, x='danceability', y='loudness', template=\"plotly_dark\", color='popularity')\n\n# popular songs are around 0 to -15 loudness\n# popular danceable songs are closer to 0 loudness\n# non danceable songs tend to be more unpopular than danceable songs\n# as danceability increases, the loudness compresses","output":{"0":{"data":{"iframe":"6f16fb5adfbac89e8d986a28540b1d6f7752182c"},"exec_count":280,"output_type":"execute_result"}},"pos":32,"type":"cell"}
{"cell_type":"code","exec_count":285,"id":"8ff5b6","input":"px.scatter(df, x = \"danceability\", y = \"acousticness\", color = \"music_genre\", template=\"plotly_dark\")","output":{"0":{"data":{"iframe":"3242ef595f4232bd67b75da07b03fa88b428565b"},"exec_count":285,"output_type":"execute_result"}},"pos":34,"type":"cell"}
{"cell_type":"code","exec_count":30,"id":"502fd0","input":"px.scatter_3d(df, x = \"speechiness\", y = \"duration_ms\", z = \"popularity\", color = \"music_genre\", template = \"plotly_dark\")\n\n# alternative and country are extremely similar here\n# rock popularity > 50; duration < 1M; speechiness < .6\n# blues popularity < 50; duration ~< 1M; speechiness < .6\n    # separated by rock by ppularity (and few outliers in popularity and duration)\n# classical has widest range of popularity and comparitively wide range of duration and fairly wide range of speechiness (overall widest ranges)\n\n# distinct genre differences:\n    # Classical vs Hip Hop\n    # Rock vs Blues\n    # Electronic vs Hip Hop\n    # Electronic vs Rock\n    # Alternative vs Classical\n    # Rap vs Classical\n    # Rap vs Rock\n    # Country vs Anime\n    # Jazz vs Hip Hop\n    # Jazz vs Rock\n    # Jazz vs Rap\n    # Anime vs Jazz (?)\n    # Alternative vs Anime\n    # Anime vs Hip Hop","output":{"0":{"data":{"iframe":"b75b02317c77b32793ea83c04adcae0299301687"},"exec_count":30,"output_type":"execute_result"}},"pos":25,"type":"cell"}
{"cell_type":"code","exec_count":33,"id":"f5cf3f","input":"px.scatter(df, x='danceability', y='acousticness', template=\"plotly_dark\", color='popularity')\n\n# highly popular danceable songs are low acoustic\n# non popular danceable songs are high acoustic\n# overall high acousticness correlates with low popularity and low acousticness correlates with high popularity\n# danceability and acousticness are not correlated","output":{"0":{"data":{"iframe":"c54db1461d31b0c4081ef6e9e778fc01c0e32951"},"exec_count":33,"output_type":"execute_result"}},"pos":35,"type":"cell"}
{"cell_type":"code","exec_count":34,"id":"337f55","input":"df.columns","output":{"0":{"data":{"text/plain":"Index(['popularity', 'acousticness', 'danceability', 'duration_ms', 'energy',\n       'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n       'speechiness', 'tempo', 'valence', 'music_genre'],\n      dtype='object')"},"exec_count":34,"output_type":"execute_result"}},"pos":12,"type":"cell"}
{"cell_type":"code","exec_count":60,"id":"9c4ea9","input":"df.tail()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>popularity</th>\n      <th>acousticness</th>\n      <th>danceability</th>\n      <th>duration_ms</th>\n      <th>energy</th>\n      <th>instrumentalness</th>\n      <th>key</th>\n      <th>liveness</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>tempo</th>\n      <th>valence</th>\n      <th>music_genre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>49994</th>\n      <td>56.0</td>\n      <td>0.13300</td>\n      <td>0.849</td>\n      <td>237667.0</td>\n      <td>0.660</td>\n      <td>0.000008</td>\n      <td>C</td>\n      <td>0.296</td>\n      <td>-7.195</td>\n      <td>Major</td>\n      <td>0.0516</td>\n      <td>99.99</td>\n      <td>0.629</td>\n      <td>Hip-Hop</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>72.0</td>\n      <td>0.15700</td>\n      <td>0.709</td>\n      <td>251860.0</td>\n      <td>0.362</td>\n      <td>0.000000</td>\n      <td>B</td>\n      <td>0.109</td>\n      <td>-9.814</td>\n      <td>Major</td>\n      <td>0.0550</td>\n      <td>122.04</td>\n      <td>0.113</td>\n      <td>Hip-Hop</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>51.0</td>\n      <td>0.00597</td>\n      <td>0.693</td>\n      <td>189483.0</td>\n      <td>0.763</td>\n      <td>0.000000</td>\n      <td>D</td>\n      <td>0.143</td>\n      <td>-5.443</td>\n      <td>Major</td>\n      <td>0.1460</td>\n      <td>131.08</td>\n      <td>0.395</td>\n      <td>Hip-Hop</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>65.0</td>\n      <td>0.08310</td>\n      <td>0.782</td>\n      <td>262773.0</td>\n      <td>0.472</td>\n      <td>0.000000</td>\n      <td>G</td>\n      <td>0.106</td>\n      <td>-5.016</td>\n      <td>Minor</td>\n      <td>0.0441</td>\n      <td>75.89</td>\n      <td>0.354</td>\n      <td>Hip-Hop</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>67.0</td>\n      <td>0.10200</td>\n      <td>0.862</td>\n      <td>267267.0</td>\n      <td>0.642</td>\n      <td>0.000000</td>\n      <td>F#</td>\n      <td>0.272</td>\n      <td>-13.652</td>\n      <td>Minor</td>\n      <td>0.1010</td>\n      <td>99.20</td>\n      <td>0.765</td>\n      <td>Hip-Hop</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"       popularity  acousticness  danceability  duration_ms  energy  \\\n49994        56.0       0.13300         0.849     237667.0   0.660   \n49996        72.0       0.15700         0.709     251860.0   0.362   \n49997        51.0       0.00597         0.693     189483.0   0.763   \n49998        65.0       0.08310         0.782     262773.0   0.472   \n49999        67.0       0.10200         0.862     267267.0   0.642   \n\n       instrumentalness key  liveness  loudness   mode  speechiness   tempo  \\\n49994          0.000008   C     0.296    -7.195  Major       0.0516   99.99   \n49996          0.000000   B     0.109    -9.814  Major       0.0550  122.04   \n49997          0.000000   D     0.143    -5.443  Major       0.1460  131.08   \n49998          0.000000   G     0.106    -5.016  Minor       0.0441   75.89   \n49999          0.000000  F#     0.272   -13.652  Minor       0.1010   99.20   \n\n       valence music_genre  \n49994    0.629     Hip-Hop  \n49996    0.113     Hip-Hop  \n49997    0.395     Hip-Hop  \n49998    0.354     Hip-Hop  \n49999    0.765     Hip-Hop  "},"exec_count":60,"output_type":"execute_result"}},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":7,"id":"11ef5d","input":"df.info()","output":{"0":{"name":"stdout","output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50000 entries, 0 to 49999\nData columns (total 14 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   popularity        50000 non-null  float64\n 1   acousticness      50000 non-null  float64\n 2   danceability      50000 non-null  float64\n 3   duration_ms       50000 non-null  float64\n 4   energy            50000 non-null  float64\n 5   instrumentalness  50000 non-null  float64\n 6   key               50000 non-null  object \n 7   liveness          50000 non-null  float64\n 8   loudness          50000 non-null  float64\n 9   mode              50000 non-null  object \n 10  speechiness       50000 non-null  float64\n 11  tempo             50000 non-null  float64\n 12  valence           50000 non-null  float64\n 13  music_genre       50000 non-null  object \ndtypes: float64(11), object(3)\nmemory usage: 5.3+ MB\n"}},"pos":10,"type":"cell"}
{"cell_type":"markdown","id":"17a781","input":"# visuals:\n\n","pos":21,"type":"cell"}
{"cell_type":"markdown","id":"25717c","input":"# [Markdown Guide cheat Sheet](https://www.markdownguide.org/cheat-sheet/)\n\n","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"3705dd","input":"# Naïve Bayes","pos":6,"type":"cell"}
{"cell_type":"markdown","id":"9aa279","input":"## Dropping things:\n\n","pos":4,"type":"cell"}
{"cell_type":"markdown","id":"9d0875","input":"## Functions","pos":2.5,"type":"cell"}
{"cell_type":"markdown","id":"afd69b","input":"# table dimensions, columns, etc.\n\n","pos":9,"type":"cell"}
{"cell_type":"markdown","id":"bba42e","input":"# Info:\n\n- ### instrumentalness: vocals in a track\n\n- ### speechiness: detects the pressents of vocal words in a track\n\n- ### music genre: 10 different types\n\t0. Electronic\n    1. Classical\n    2. Jazz\n    3. anime\n    4. Rock\n    5. country\n    6. Rap\n    7. Blues\n    8. Hip-Hop\n    9.Alternative\n\n# problems with table:\n\n1. ~~negative duration~~\n2. ~~missing tempos~~\n3. ~~rows 10000-10005 are nan values for every column~~\n4. negative loudness\n\n","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"cc9b7a","input":"## imports","pos":1.5,"type":"cell"}
{"end":1657219432960,"exec_count":155,"id":"ac5efa","input":"#px.bar(confusion_matrix(y_test, y_hat), x=y_test, y=y_hat, color=y_hat)","kernel":"ds_env","pos":8.5,"start":1657219432943,"state":"done","type":"cell"}
{"id":0,"time":1657206043877,"type":"user"}
{"last_load":1657202870921,"type":"file"}