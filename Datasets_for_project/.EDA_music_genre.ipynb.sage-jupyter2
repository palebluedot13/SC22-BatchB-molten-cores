{"backend_state":"running","connection_file":"/projects/afffd160-11c4-4b0e-8185-cf29c729cf98/.local/share/jupyter/runtime/kernel-ea9c426d-61e5-4d27-91e8-998d882e4cd9.json","kernel":"ds_env","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1657301163761,"exec_count":1,"id":"c34954","input":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport plotly.io as pio\nimport sklearn\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport copy\nimport sklearn\nimport xgboost as xgb\n\nfrom sklearn import tree\nfrom sklearn import preprocessing\nfrom sklearn import utils\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split # Import train_test_split function\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\nfrom sklearn.metrics import precision_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\nfrom xgboost import XGBClassifier\nfrom IPython.display import Image\nfrom subprocess import call","kernel":"ds_env","no_halt":true,"pos":6,"start":1657301161664,"state":"done","type":"cell"}
{"cell_type":"code","end":1657301163785,"exec_count":2,"id":"94afd0","input":"#This function returns the accuracy of tests\ndef getScore(y_test,y_hat):\n    labels = ['Electronic', 'Anime', 'Jazz', 'Alternative', 'Country', 'Rap', 'Blues', 'Rock', 'Classical', 'Hip-Hop']\n    print((np.sum((y_test - y_hat)**2))/len(y_test) )#mean squared error\n    print(classification_report(y_test, y_hat,target_names=[i+\":\" for i in labels]))\n\n#This function replaces labels, such as Jazz, Rock, Rap, etc. with numbers. Each label now carries it's own number\n\ndef stringToInt(dataFrame,col):\n    test = {}\n    for i in dict(enumerate(dataFrame[col].unique())).items():#is a dictionary of the keys and corespodening number\n        #makes it so the keys and values of the dictionary switch\n        test[i[1]]=i[0]\n    print(test,'\\n')\n    return dataFrame[col].map(test)","kernel":"ds_env","no_halt":true,"pos":8,"start":1657301163772,"state":"done","type":"cell"}
{"cell_type":"code","end":1657301164407,"exec_count":3,"id":"5fc9dd","input":"#getting dataframe\ndf = pd.read_csv(\"music_genre.csv\")\n\n#dropping columns\nbadInfo = [\"instance_id\",\"obtained_date\",\"artist_name\",\"track_name\"]\ndf.drop(columns=badInfo,axis=1,inplace=True)\n\n#dropping null rows\ndf.dropna(inplace=True)\ndf.reset_index(drop=True, inplace=True) #Very good practice to reset how your rows are counted when you drop rows.\n\n#fixing the problem with 'tempo' column\ndf[\"tempo\"]=df[\"tempo\"].replace(\"?\",np.nan)\ndf[\"tempo\"] = df[\"tempo\"].astype(\"float\")\ndf[\"tempo\"]=df.groupby(\"music_genre\")[\"tempo\"].transform(lambda x: x.fillna(x.mean(skipna=True)))\ndf['tempo'] = np.around(df['tempo'],2)\n\n#fixing the problem with 'duration' column\ndf[\"duration_ms\"]=df[\"duration_ms\"].replace(-1.0,np.nan)\ndf[\"duration_ms\"]=df.groupby(\"music_genre\")[\"duration_ms\"].transform(lambda x: x.fillna(x.mean(skipna=True)))\ndf['duration_ms'] = np.around(df['duration_ms'],2)\n\n#changing the values from string to int\ndf['key'] = stringToInt(df,'key')\ndf['mode'] = stringToInt(df,'mode')\ndf['music_genre_name'] = df['music_genre']\ndf['music_genre'] = stringToInt(df,'music_genre')\n\npio.templates.default = \"plotly_dark\"\n\ndfxg = copy.deepcopy(df)","kernel":"ds_env","no_halt":true,"output":{"0":{"name":"stdout","text":"{'A#': 0, 'D': 1, 'G#': 2, 'C#': 3, 'F#': 4, 'B': 5, 'G': 6, 'F': 7, 'A': 8, 'C': 9, 'E': 10, 'D#': 11} \n\n{'Minor': 0, 'Major': 1} \n\n{'Electronic': 0, 'Anime': 1, 'Jazz': 2, 'Alternative': 3, 'Country': 4, 'Rap': 5, 'Blues': 6, 'Rock': 7, 'Classical': 8, 'Hip-Hop': 9} \n\n"}},"pos":9,"start":1657301163797,"state":"done","type":"cell"}
{"cell_type":"code","end":1657301164455,"exec_count":4,"id":"893791","input":"#Setting X to be all the input columns \nX = df.loc[:,df.columns[:-2]]\n\n\n#Setting y to be the desired column\ny= df['music_genre']#what we want\n\n#Splitting test and train ratio\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n#Scaling X variables\nsc = preprocessing.StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform (X_test)\n\n#for heat map\nlabels = ['Electronic', 'Anime', 'Jazz', 'Alternative', 'Country', 'Rap', 'Blues', 'Rock', 'Classical', 'Hip-Hop']","kernel":"ds_env","no_halt":true,"pos":12,"start":1657301164426,"state":"done","type":"cell"}
{"cell_type":"code","end":1657301165154,"exec_count":5,"id":"c94c1e","input":"px.bar(df.sort_values(by=[\"music_genre_name\"]), x='popularity', y='acousticness', color='music_genre_name')\n\n# non danceable songs are of the highest acoustecness\n# danceability and popularity are not correlated\n# for each popularity, the least danceable songs tend to have the highest acousticness (at least until about 45 popularity)***","kernel":"ds_env","no_halt":true,"output":{"0":{"data":{"iframe":"53a8a98d94e0af1955fc5ff3a0ebb71ad785559f"}}},"pos":15,"start":1657301164466,"state":"done","type":"cell"}
{"cell_type":"code","end":1657301165785,"exec_count":6,"id":"c0ea89","input":"df = df.sort_values(by=[\"key\"])\npx.bar(df, x='music_genre_name', y='tempo',color='key')\n\n# tempo is highest for classical\n# tempo is lowest for electronic\n# clear pattern in tempo per genre","kernel":"ds_env","no_halt":true,"output":{"0":{"data":{"iframe":"5dd92e374cbaa6de70fbdb52c87fcf1ba3acdf9d"}}},"pos":16,"start":1657301165166,"state":"done","type":"cell"}
{"cell_type":"code","end":1657301166252,"exec_count":7,"id":"302cb2","input":"#shows that we have an equal amount of each genre\ndf[\"music_genre_name\"].hist(figsize = (10, 10))","kernel":"ds_env","no_halt":true,"output":{"0":{"data":{"text/plain":"<AxesSubplot:>"},"exec_count":7},"1":{"data":{"image/png":"cc805b90cde527f48384ee6eda4008a8b58921a7","text/plain":"<Figure size 720x720 with 1 Axes>"},"metadata":{"needs_background":"light"}}},"pos":17,"start":1657301165795,"state":"done","type":"cell"}
{"cell_type":"code","end":1657301166746,"exec_count":8,"id":"b856e5","input":"px.scatter_3d(df, x = \"acousticness\", y = \"tempo\", z = \"popularity\", color = \"music_genre_name\", size=\"duration_ms\",size_max=50)","kernel":"ds_env","no_halt":true,"output":{"0":{"data":{"iframe":"8aeef112db19470dbc41ae262cce1d6dcdd80900"}}},"pos":18,"start":1657301166257,"state":"done","type":"cell"}
{"cell_type":"code","end":1657301181640,"exec_count":10,"id":"6f6337","input":"\n#Building a model\nmodel = LogisticRegression()\n\n\n#Fitting our data\nmodel.fit(X_train, y_train)\n\n\n#Prediction of X_test\ny_pred = model.predict(X_test)\n\n\n#Finding out accurasy of train variables\nX_train_acc = model.score(X_train, y_train)\nprint(\"The Accuracy for Training Set is {}\".format(X_train_acc*100))\n\n\n#Finding out accuracy of test variables \ntest_acc = model.score(X_test, y_test)\nprint(\"The Accuracy for Test Set is {}\".format(test_acc*100))\n\n\n#Printing classification report\ngetScore(y_test,y_pred)\n","kernel":"ds_env","no_halt":true,"output":{"0":{"name":"stdout","text":"The Accuracy for Training Set is 53.1575\nThe Accuracy for Test Set is 53.059999999999995\n7.4106\n              precision    recall  f1-score   support\n\n Electronic:       0.59      0.60      0.59       981\n      Anime:       0.63      0.63      0.63      1008\n       Jazz:       0.48      0.41      0.44       996\nAlternative:       0.38      0.30      0.33       996\n    Country:       0.47      0.60      0.53      1021\n        Rap:       0.45      0.42      0.43       977\n      Blues:       0.51      0.46      0.48      1012\n       Rock:       0.51      0.65      0.57       984\n  Classical:       0.78      0.79      0.79       972\n    Hip-Hop:       0.48      0.46      0.47      1053\n\n    accuracy                           0.53     10000\n   macro avg       0.53      0.53      0.53     10000\nweighted avg       0.53      0.53      0.53     10000\n\n"}},"pos":22,"start":1657301180600,"state":"done","type":"cell"}
{"cell_type":"code","end":1657301182326,"exec_count":11,"id":"05bdea","input":"#Confusion matrix\n\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g', xticklabels=labels, yticklabels=labels)","kernel":"ds_env","no_halt":true,"output":{"0":{"data":{"text/plain":"<AxesSubplot:>"},"exec_count":11},"1":{"data":{"image/png":"53e73109c3f13c3a258204b6c53bd0d33a41bf5a","text/plain":"<Figure size 432x288 with 2 Axes>"},"metadata":{"needs_background":"light"}}},"pos":23,"start":1657301181647,"state":"done","type":"cell"}
{"cell_type":"code","end":1657301183065,"exec_count":12,"id":"934ab6","input":"#Building a model\ngnb = GaussianNB()\n\n#Fitting data \ny_hat = gnb.fit(X_train, y_train).predict(X_test)\n\n#Confusion Matrix \nsns.heatmap(confusion_matrix(y_test, y_hat), annot=True, fmt='g', xticklabels=labels, yticklabels=labels)","kernel":"ds_env","no_halt":true,"output":{"0":{"data":{"text/plain":"<AxesSubplot:>"},"exec_count":12},"1":{"data":{"image/png":"cae30d8979f66bd8573b0275e13810561487c933","text/plain":"<Figure size 432x288 with 2 Axes>"},"metadata":{"needs_background":"light"}}},"pos":26,"start":1657301182334,"state":"done","type":"cell"}
{"cell_type":"code","end":1657301183105,"exec_count":13,"id":"9f17ab","input":"# Accuracy of the test\ngetScore(y_test,y_hat)","kernel":"ds_env","no_halt":true,"output":{"0":{"name":"stdout","text":"8.4072\n              precision    recall  f1-score   support\n\n Electronic:       0.54      0.43      0.48       981\n      Anime:       0.67      0.38      0.49      1008\n       Jazz:       0.41      0.31      0.36       996\nAlternative:       0.36      0.21      0.26       996\n    Country:       0.29      0.79      0.43      1021\n        Rap:       0.42      0.45      0.43       977\n      Blues:       0.50      0.23      0.31      1012\n       Rock:       0.49      0.33      0.40       984\n  Classical:       0.65      0.85      0.74       972\n    Hip-Hop:       0.44      0.47      0.46      1053\n\n    accuracy                           0.45     10000\n   macro avg       0.48      0.45      0.43     10000\nweighted avg       0.48      0.45      0.43     10000\n\n"}},"pos":27,"scrolled":true,"start":1657301183079,"state":"done","type":"cell"}
{"cell_type":"code","end":1657301183881,"exec_count":14,"id":"0866a2","input":"#Building a model\nclf = DecisionTreeClassifier(max_depth = 2, random_state = 0)\n\n#Fitting in our data\nclf = clf.fit(X_train,y_train)\n\n#Predicting X_test\ny_pred = clf.predict(X_test)\n\n\n#Accuracy of the test\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n\nfig, axe = plt.subplots(figsize=(36,30))\ntree.plot_tree(clf, ax = axe, fontsize=15)","kernel":"ds_env","no_halt":true,"output":{"0":{"name":"stdout","text":"Accuracy: 0.3196\n"},"1":{"data":{"text/plain":"[Text(0.5, 0.8333333333333334, 'X[0] <= 0.214\\ngini = 0.9\\nsamples = 40000\\nvalue = [4019, 3992, 4004, 4004, 3979, 4023, 3988, 4016, 4028\\n3947]'),\n Text(0.25, 0.5, 'X[8] <= -1.256\\ngini = 0.852\\nsamples = 22128\\nvalue = [3379, 3912, 3145, 1590, 2460, 39, 3603, 49, 3801\\n150]'),\n Text(0.125, 0.16666666666666666, 'gini = 0.405\\nsamples = 3834\\nvalue = [47, 389, 348, 6, 22, 0, 110, 1, 2909, 2]'),\n Text(0.375, 0.16666666666666666, 'gini = 0.842\\nsamples = 18294\\nvalue = [3332, 3523, 2797, 1584, 2438, 39, 3493, 48, 892, 148]'),\n Text(0.75, 0.5, 'X[10] <= -0.148\\ngini = 0.826\\nsamples = 17872\\nvalue = [640, 80, 859, 2414, 1519, 3984, 385, 3967, 227, 3797]'),\n Text(0.625, 0.16666666666666666, 'gini = 0.814\\nsamples = 10207\\nvalue = [433, 52, 687, 1638, 1392, 1147, 327, 3437, 219, 875]'),\n Text(0.875, 0.16666666666666666, 'gini = 0.701\\nsamples = 7665\\nvalue = [207, 28, 172, 776, 127, 2837, 58, 530, 8, 2922]')]"},"exec_count":14},"2":{"data":{"image/png":"b19e2852814556100325f12d068297e63a656c14","text/plain":"<Figure size 2592x2160 with 1 Axes>"},"metadata":{"needs_background":"light"}}},"pos":31,"start":1657301183114,"state":"done","type":"cell"}
{"cell_type":"code","end":1657301186310,"exec_count":15,"id":"4a73c3","input":"param_grid = {'max_depth': np.arange(3, 6)}\n\ntree = GridSearchCV(DecisionTreeClassifier(), param_grid)\n\ntree.fit(X_train, y_train)\ntree_pred = tree.predict_proba(X_test)[:, 1]\n\n\nprint (\"DecisionTree: Area under the ROC curve = {}\".format(tree))","kernel":"ds_env","no_halt":true,"output":{"0":{"name":"stdout","text":"DecisionTree: Area under the ROC curve = GridSearchCV(estimator=DecisionTreeClassifier(),\n             param_grid={'max_depth': array([3, 4, 5])})\n"}},"pos":32,"start":1657301183893,"state":"done","type":"cell"}
{"cell_type":"code","end":1657301186335,"exec_count":16,"id":"b94ede","input":"print(X_train.shape)    # Prints out the shape of the variable.\nprint(X_test.shape)     # Prints out the shape of the variable.\nprint(y_train.shape)    # Prints out the shape of the variable.\nprint(y_test.shape)     # Prints out the shape of the variable.","kernel":"ds_env","no_halt":true,"output":{"0":{"name":"stdout","text":"(40000, 13)\n(10000, 13)\n(40000,)\n(10000,)\n"}},"pos":36,"start":1657301186321,"state":"done","type":"cell"}
{"cell_type":"code","end":1657301188655,"exec_count":17,"id":"8bbf1b","input":"tst = RandomForestClassifier(max_depth=2, random_state=0)   # RandomForestRegressor is added.\n\ny_pred1 = tst.fit(X_train, y_train).predict(X_test)         # Fits the model and predicts\n\nprint(\"\\n------------------------------------------------------\\n\")\ngetScore(y_test, y_pred1)\nprint(\"\\n------------------------------------------------------\\n\")\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred1))\nprint(\"\\n------------------------------------------------------\\n\")","kernel":"ds_env","no_halt":true,"output":{"0":{"name":"stdout","text":"\n------------------------------------------------------\n\n9.5346\n              precision    recall  f1-score   support\n\n Electronic:       0.41      0.63      0.49       981\n      Anime:       0.57      0.50      0.53      1008\n       Jazz:       0.61      0.03      0.06       996\nAlternative:       0.00      0.00      0.00       996\n    Country:       0.00      0.00      0.00      1021\n        Rap:       0.32      0.31      0.32       977\n      Blues:       0.25      0.44      0.32      1012\n       Rock:       0.36      0.84      0.50       984\n  Classical:       0.62      0.87      0.72       972\n    Hip-Hop:       0.47      0.53      0.50      1053\n\n    accuracy                           0.41     10000\n   macro avg       0.36      0.42      0.34     10000\nweighted avg       0.36      0.41      0.34     10000\n\n\n------------------------------------------------------\n\nAccuracy: 0.4131\n\n------------------------------------------------------\n\n"},"1":{"name":"stderr","text":"/projects/afffd160-11c4-4b0e-8185-cf29c729cf98/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/projects/afffd160-11c4-4b0e-8185-cf29c729cf98/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n/projects/afffd160-11c4-4b0e-8185-cf29c729cf98/miniconda3/envs/ds_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n"}},"pos":37,"start":1657301186352,"state":"done","type":"cell"}
{"cell_type":"code","end":1657301240918,"exec_count":18,"id":"f7f551","input":"\nmodel = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\ny_pred = model.fit(X_train, y_train).predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Overall Accuracy: \", accuracy)\n\ntotal_squared_error = (np.sum((y_test - y_pred)**2))\nmean_squared_error = total_squared_error/len(y_test)\nprint(mean_squared_error)\n\n#confusion matrix\nlabels = ['Electronic', 'Anime', 'Jazz', 'Alternative', 'Country', 'Rap', 'Blues', 'Rock', 'Classical', 'Hip-Hop']\n# sns.heatmap(confusion_matrix(y_test.values.argmax(axis=1), y_pred.argmax(axis=1)), annot=True, fmt='g', xticklabels=labels, yticklabels=labels)\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g', xticklabels=labels, yticklabels=labels)","kernel":"ds_env","no_halt":true,"output":{"0":{"name":"stdout","text":"Overall Accuracy:  0.6491\n5.4102\n"},"1":{"data":{"text/plain":"<AxesSubplot:>"},"exec_count":18},"2":{"data":{"image/png":"6e962bd65b42f2367cbb713ac9b9487cd5df2cdd","text/plain":"<Figure size 432x288 with 2 Axes>"},"metadata":{"needs_background":"light"}}},"pos":40,"start":1657301188667,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"030963","input":"# ____________________________________________________________________________________________________\n\n","pos":1,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"06bf11","input":"# ____________________________________________________________________________________________________\n\n","pos":28,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"1e9d0d","input":"# ____________________________________________________________________________________________________\n\n","pos":4,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"2d11c1","input":"# ____________________________________________________________________________________________________\n\n","pos":10,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"329a49","input":"## Plot\n\n","pos":14,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"33a848","input":"# ____________________________________________________________________________________________________\n\n","pos":7,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"36b999","input":"##### [Markdown Guide cheat Sheet](https://www.markdownguide.org/cheat-sheet/)\n\n","pos":3,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"474e2e","input":"## Naive Bayes \n\nAbout  Naive Bayes :\nNative Bayes is a machine learning model for classification that uses the Bayes Theorem(\t<img src=\"https://s0.wp.com/latex.php?latex=%5Ctextrm%7BP%28H+%5Ctextbar+E%29+%3D+%7D+%C2%A0%5Cfrac%7B%5Ctextrm%7B+P%28E+%5Ctextbar+H%29+%2A+P%28H%29%7D%7D+%7B%5Ctextrm%7BP%28E%29%7D%7D&bg=ffffff&fg=000&s=0&c=20201002\" alt=\"img\" width=\"200\"/>\t)\n\n  -  P(H) is the probability of hypothesis H being true. This is known as the prior probability.\n  -  P(E) is the probability of the evidence(regardless of the hypothesis).\n  -  P(E|H) is the probability of the evidence given that hypothesis is true.\n  -  P(H|E) is the probability of the hypothesis given that the evidence is there.\n\nGood at  predicting:\n\n- Classical\n\n\nOkay at predicting:\n\n- Electronic\n- Anime\n- Hip-Hop\n\nBad at predicting:\n\n- everything else\n\n","pos":25,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"50532f","input":"# ____________________________________________________________________________________________________\n\n","pos":33,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"51ba4c","input":"## Notes:\n\n- ### Instrumentalness: vocals in a track\n\n- ### Speechiness: detects the pressents of vocal words in a track\n\n- ### Music genre: (10 different types)\n\t0. Electronic\n    1. Classical\n    2. Jazz\n    3. anime\n    4. Rock\n    5. country\n    6. Rap\n    7. Blues\n    8. Hip-Hop\n    9. Alternative\n\n# Problems with table:\n\n- [x] negative duration\n- [x] missing tempos\n- [x] rows 10000-10005 are nan values for every column\n- [ ] negative loudness\n\n","pos":2,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"54f4e0","input":"# Music Genre Prediction: Molten Cores\n\n<img src=\"https://www.warcrafttavern.com/wp-content/uploads/2020/10/WoW-Classic-Molten-Core-Guide-1024x729.jpg\" alt=\"img\" width=\"95%\"/>\n\n","pos":0,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"6c877e","input":"## Classification Trees\n\n","pos":29,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"807a79","input":"## Random Forest ","pos":34,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"8db7d8","input":"## Xgboost:\nXgBoost stands for Extreme Gradient Boosting","pos":39,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"927e9f","input":"# ____________________________________________________________________________________________________","pos":41,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"92dffd","input":"# ____________________________________________________________________________________________________\n\n","pos":8.25,"type":"cell"}
{"cell_type":"markdown","id":"a93d3f","input":"## All Libaries & Imports \n\n","pos":5,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"b61414","input":"# ____________________________________________________________________________________________________","pos":38,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"bc10b3","input":"# Functions\n\n","pos":7.5,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"c530eb","input":"# ____________________________________________________________________________________________________\n\n","pos":20,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"d3ff73","input":"## Spiting and scaling data\n\n","pos":11,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"ea10dc","input":"# Fixing problems with the Dataset\n\n","pos":8.5,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"ef7213","input":"# ____________________________________________________________________________________________________\n\n","pos":13,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"fb664e","input":"# ____________________________________________________________________________________________________\n\n","pos":24,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"fc484d","input":"**About Classification Trees:** \n\nDecision Trees \\(DTs\\) are a non\\-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a piecewise constant approximation.\n\n**Pros**\n\n- Simple to understand and to interpret. Trees can be visualized.\n- Requires little data preparation.\n- Able to handle both numerical and categorical data.\n- Possible to validate a model using statistical tests.\n\n**Cons**\n\n- Decision\\-tree learners can create over\\-complex trees that do not generalize the data well.\n- Decision trees can be unstable because small var iations in the data might result in a completely different tree being generated\n- Predictions of decision trees are neither smooth nor continuous, but piecewise constant approximations as seen in the above figure.\n- Decision tree learners create biased trees if some classes dominate.\n\n","pos":30,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"ff8975","input":"# Logistic Regression \n\nLogistic Regression is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable.\n\nIn logistic regression, the dependent variable is a binary variable that contains data coded as 1 (yes, success, etc.) or 0 (no, failure, etc.).\n\n#### Types of LR\n\nWhen we talk about Logistic Regression in general, we usually mean Binary logistic regression, although there are other types of Logistic Regression as well.\n\nLogistic Regression can be divided into types based on the type of classification it does. With that in view, there are 3 types of Logistic Regression. Let’s talk about each of them:\n\n- Binary Logistic Regression\n- Multinomial Logistic Regression\n- Ordinal Logistic Regression\n\nIn our case, we used **Multinomial Logistic Regression**\n\nMultinomial Logistic Regression deals with cases when the target or independent variable has three or more possible values.\n\n**For example**, the use of Chest X-ray images as features that give indication about one of the three possible outcomes (No disease, Viral Pneumonia, COVID-19). The multinomial Logistic Regression will use the features to classify the example into one of the three possible outcomes in this case. There can of course be more than three possible values of the target variable. in our case, there are **10**.\n\n","pos":21,"state":"done","type":"cell"}
{"end":1657301180550,"exec_count":9,"id":"73974d","input":"px.scatter(df.sort_values(by=[\"tempo\"]), x = \"loudness\", y = \"tempo\", color = \"music_genre_name\", size=\"duration_ms\",size_max=50,trendline=\"lowess\")","kernel":"ds_env","no_halt":true,"output":{"0":{"data":{"iframe":"a8b31041c46b0e886f94a38ff36ba016d3dc59a6"}}},"pos":19,"start":1657301166756,"state":"done","type":"cell"}
{"end":1657301432812,"exec_count":19,"id":"50ed78","input":"getScore(y_test, y_pred)","kernel":"ds_env","output":{"0":{"name":"stdout","text":"5.4102\n              precision    recall  f1-score   support\n\n Electronic:       0.74      0.70      0.72       981\n      Anime:       0.83      0.78      0.81      1008\n       Jazz:       0.64      0.63      0.63       996\nAlternative:       0.57      0.51      0.53       996\n    Country:       0.69      0.65      0.67      1021\n        Rap:       0.46      0.51      0.48       977\n      Blues:       0.70      0.65      0.67      1012\n       Rock:       0.57      0.74      0.64       984\n  Classical:       0.87      0.85      0.86       972\n    Hip-Hop:       0.49      0.49      0.49      1053\n\n    accuracy                           0.65     10000\n   macro avg       0.66      0.65      0.65     10000\nweighted avg       0.66      0.65      0.65     10000\n\n"}},"pos":40.5,"start":1657301432773,"state":"done","type":"cell"}
{"id":0,"time":1657300702949,"type":"user"}
{"last_load":1657298354397,"type":"file"}